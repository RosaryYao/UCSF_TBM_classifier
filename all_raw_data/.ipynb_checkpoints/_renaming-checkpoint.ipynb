{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('_renaming_IDchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('training_validation.csv').set_index('ensembl')\n",
    "df3 = pd.read_csv('internal_validation.csv').set_index('ensembl')\n",
    "\n",
    "df4 = pd.read_csv('combined_test.csv').set_index('ensembl')\n",
    "df5 = pd.read_csv('metadata.csv').set_index('samples')\n",
    "\n",
    "test_f = pd.read_csv('_keep_in_final.csv', header = None)\n",
    "add_from_test = df4.columns[~df4.columns.isin(test_f[0].values)]\n",
    "df3_1 = df4[add_from_test]\n",
    "\n",
    "df3_new = df3.merge(df3_1, how = \"inner\", left_index = True, right_index = True)\n",
    "df4_new = df4[test_f[0].values]\n",
    "\n",
    "# df2 and df5 remain unchanged #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = df1[df1['set'] == \"training_valid\"].drop(['set'], axis = 1)\n",
    "iv = df1[df1['set'] == \"internal validation\"].drop(['set'], axis = 1)\n",
    "test = df1[df1['set'] == \"test\"].drop(['set'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = df2.T.merge(tv, how = 'inner', left_index = True, right_on = \"ensembl\").set_index(\"newID\").drop(\"ensembl\", axis=1).T \n",
    "\n",
    "new_additional = df3_new.T.merge(iv, how = 'inner', left_index = True, right_on = \"ensembl\").set_index(\"newID\").drop(\"ensembl\", axis=1).T \n",
    "\n",
    "new_test = df4_new.T.merge(test, how = 'inner', left_index = True, right_on = \"ensembl\").set_index(\"newID\").drop(\"ensembl\", axis=1).T \n",
    "\n",
    "new_meta = df5.merge(tv, how = 'inner', left_index = True, right_on = \"ensembl\").set_index(\"newID\").drop(\"ensembl\", axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19590, 70), (19590, 196), (19590, 80), (70, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.shape, new_additional.shape, new_test.shape, new_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv('training_validation_n.csv')\n",
    "new_additional.to_csv('additional_samples.csv')\n",
    "new_test.to_csv('combined_test_n.csv')\n",
    "new_meta.to_csv('metadata_n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
